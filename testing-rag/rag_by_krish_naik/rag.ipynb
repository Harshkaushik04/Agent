{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eddc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self,page_content,metadata,encoding):\n",
    "        self.page_content=page_content\n",
    "        self.metadata=metadata\n",
    "        self.encoding=encoding\n",
    "    def __str__(self):\n",
    "        return f\"\"\"{{\"page_content\": {self.page_content}, \"metadata\": {self.metadata}}}\"\"\"\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def load(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d770a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=Document(page_content=\"Hello this is some document\",\n",
    "             metadata={\n",
    "        \"source\": \"manual.pdf\",\n",
    "        \"page\": 10,\n",
    "        \"author\": \"Gemini\",\n",
    "    },encoding=\"utf-8\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06449341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLoader:\n",
    "    def __init__(self,file_path,encoding):\n",
    "        self.file_path=file_path\n",
    "        self.encoding=encoding\n",
    "    def __str__(self):\n",
    "        return f\"{self.load()}\"\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def load(self):\n",
    "        try:\n",
    "            with open(self.file_path,encoding=self.encoding) as f:\n",
    "                loaded_text=f.read()\n",
    "        except:\n",
    "            raise Exception(\"couldnt load file\")\n",
    "        loaded_document=Document(page_content=loaded_text,metadata={\"source\":self.file_path},encoding=self.encoding)\n",
    "        return loaded_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_document=TextLoader(\"data/text_files/context8.txt\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c74f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_document.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49903a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b82318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectoryLoader:\n",
    "    def __init__(self,directory_path,file_type,encoding,loader_cls):\n",
    "        self.directory_path=directory_path\n",
    "        self.file_type=file_type\n",
    "        self.encoding=encoding\n",
    "        self.loader_cls=loader_cls\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"DirectoryLoader(docs={self.custom_load()})\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def custom_load(self):\n",
    "        docs=[]\n",
    "        def recurse():\n",
    "            for entry in os.listdir(self.directory_path):\n",
    "                full_path = os.path.join(self.directory_path, entry)\n",
    "                if os.path.isdir(full_path):\n",
    "                    recurse(full_path)                 # recursive call\n",
    "                elif entry.endswith(self.file_type):\n",
    "                    loader = self.loader_cls(full_path, encoding=self.encoding)\n",
    "                    docs.append(loader.load())\n",
    "        recurse()\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd623ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_loader_txt=DirectoryLoader(directory_path=\"data/text_files\",file_type=\".txt\",encoding=\"utf-8\",loader_cls=TextLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914715cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=dir_loader_txt.custom_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0800704",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir_loader_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader,PyMuPDFLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "# since this implements a different class called Blob, this is kinda tough to implement(though implementable) and also uses pypdf library=>lets just use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_loader_pdf=DirectoryLoader(path=\"data/papers\",glob=\"**/*.pdf\",loader_cls=PyMuPDFLoader,show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=dir_loader_pdf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b494fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(docs,chunk_size=1000,chunk_overlap=200):\n",
    "    text_spliter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\",\" \",\"\\n\",\"\\n\\n\"]\n",
    "    )\n",
    "    splitted_chunks=text_spliter.split_documents(docs)\n",
    "    print(f\"split {len(docs)} documents into {len(splitted_chunks)} chunks\")\n",
    "    if splitted_chunks:\n",
    "        print(\"Example:\")\n",
    "        print(f\"{type(splitted_chunks[0])}\")\n",
    "        print(f\"{splitted_chunks[0]}\")\n",
    "split_documents(docs,1000,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import chromadb\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00680e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum,auto\n",
    "\n",
    "class Processor(Enum):\n",
    "    CPU=auto()\n",
    "    GPU=auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import gc\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d305ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_memory(model):\n",
    "    if model:\n",
    "        del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if torch.cuda.is_available():\n",
    "        free=torch.cuda.mem_get_info()[0]/1024**3\n",
    "        print(f\"    [SYSTEM] VRAM Free: {free:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel:\n",
    "    def __init__(self,model_path,processor,n_ctx,n_batch):\n",
    "        self.model_path=model_path\n",
    "        self.processor=processor\n",
    "        self.n_ctx=n_ctx\n",
    "        self.n_batch=n_batch\n",
    "        self.model=None\n",
    "    def load(self):\n",
    "        if self.processor==Processor.CPU:\n",
    "            self.model=Llama(model_path=self.model_path,\n",
    "                        n_gpu_layers=0,\n",
    "                        n_ctx=self.n_ctx,\n",
    "                        n_batch=self.n_batch,\n",
    "                        verbose=False)\n",
    "        else:\n",
    "            self.model=Llama(model_path=self.model_path,\n",
    "                             n_gpu_layers=-1,\n",
    "                             n_batch=self.n_batch,\n",
    "                             n_ctx=self.n_ctx,\n",
    "                             verbose=False)\n",
    "    def unload(self):\n",
    "        clean_memory(self.model)\n",
    "    def embed(self,texts,show_progress_bar=False):\n",
    "        total=len(texts)\n",
    "        i=0\n",
    "        embeddings=[]\n",
    "        for text in texts:\n",
    "            i+=1\n",
    "            if show_progress_bar and i%50==0:\n",
    "                print(f\"{i}/{total} texts done\")\n",
    "            full_data=self.model.create_embedding(text)\n",
    "            embedded_vector=full_data[\"data\"][0][\"embedding\"]\n",
    "            embeddings.append(embedded_vector)\n",
    "        return np.array(embeddings, dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{path.abspath(path.join(os.getcwd(),\"../../models/gte-Qwen2-1.5B-instruct-f16.gguf\"))}\")\n",
    "embeddingModel=EmbeddingModel(model_path=path.abspath(path.join(os.getcwd(),\"../../models/gte-Qwen2-1.5B-instruct-f16.gguf\")),\n",
    "                              processor=Processor.GPU,\n",
    "                              n_ctx=8192*3,\n",
    "                              n_batch=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ec63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddingModel.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db651d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingModel.unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3150ef1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
